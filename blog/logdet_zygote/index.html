<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/katex/katex.min.css"> <link rel=stylesheet  href="/libs/highlight/styles/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/hypertext.css"> <link rel=icon  href="/assets/favicon.png"> <title>Differentiate the log-determinant of a matrix on GPU using Zygote.jl</title> <header> <h1 style="color:#283747">Shane Chu</h1> <nav> <a href="/" class=current >About</a> | <a href="/research">Research</a> | <a href="/blog">Notes</a> | <a href="/tags/">Tags</a> | <a href="/Shane_CV.pdf">CV</a> | <a href="/others">Others</a> <hr/> </nav> </header> <div class=franklin-content ><h2 id=differentiate_the_log-determinant_of_a_matrix_on_gpu_using_zygotejl ><a href="#differentiate_the_log-determinant_of_a_matrix_on_gpu_using_zygotejl" class=header-anchor >Differentiate the log-determinant of a matrix on GPU using Zygote.jl</a></h2> <h3 id=log-determinant_in_a_computational_graph ><a href="#log-determinant_in_a_computational_graph" class=header-anchor >Log-determinant in a computational graph</a></h3> <p>Does the computation of log-determinant of a matrix ever occur in the computational graph of a neural network?</p> <p>Surprisingly, it does. This arises in the context of Sparse Variational Gaussian Process &#40;SVGP&#41;.</p> <p>In SVGP, our goal is to maximize a quantity known as the evidence lower bound &#40;ELBO&#41;. The ELBO comprises of two terms, which basically says:</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mtable rowspacing=0.25em  columnalign=right  columnspacing=""><mtr><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mtext>ELBO</mtext><mo>=</mo><mtext>expected log likelihood term</mtext><mo>−</mo><mtext>KL divergence term</mtext></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex"> \begin{align*} \text{ELBO} = \text{expected log likelihood term} - \text{KL divergence term} \end{align*} </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.5em;vertical-align:-0.5em;"></span><span class=mord ><span class=mtable ><span class=col-align-r ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1em;"><span style="top:-3.16em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord text"><span class=mord >ELBO</span></span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span><span class="mord text"><span class=mord >expected log likelihood term</span></span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >−</span><span class=mspace  style="margin-right:0.2222em;"></span><span class="mord text"><span class=mord >KL divergence term</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.5em;"><span></span></span></span></span></span></span></span></span></span></span></span> <p>One could check, e.g. <a href="https://towardsdatascience.com/sparse-and-variational-gaussian-process-what-to-do-when-data-is-large-2d3959f430e7">Wei Yi&#39;s excellent tutorial</a> or James Hensman&#39;s <a href="https://arxiv.org/pdf/1309.6835.pdf">Gaussian Process for big data</a> for the derivation of ELBO for SVGP. In short, the KL divergence term in ELBO is expressed as:</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mtable rowspacing=0.25em  columnalign=right  columnspacing=""><mtr><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mtext>KL divergence term in ELBO</mtext><mo>=</mo><mstyle mathcolor=grey ><mfrac><mn>1</mn><mn>2</mn></mfrac><mo fence=false  stretchy=true  minsize=2.4em  maxsize=2.4em >[</mo></mstyle><mi>log</mi><mo>⁡</mo><mfrac><mn>1</mn><mrow><mi>det</mi><mo>⁡</mo><mi mathvariant=normal >Σ</mi></mrow></mfrac><mo>+</mo><mstyle mathcolor=grey ><mi>n</mi><mo>+</mo><mi>μ</mi><mi mathvariant=normal >⊤</mi><mi>μ</mi><mo>+</mo><mtext>trace</mtext><mo stretchy=false >(</mo><mi mathvariant=normal >Σ</mi><mo stretchy=false >)</mo><mo fence=false  stretchy=true  minsize=2.4em  maxsize=2.4em >]</mo></mstyle></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex"> \begin{align*} \text{KL divergence term in ELBO} = {\color{grey}\frac{1}{2}\bigg[}\log\frac{1}{\det\Sigma} + {\color{grey}n + \mu\top\mu + \text{trace}(\Sigma)\bigg]} \end{align*} </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:2.7em;vertical-align:-1.1em;"></span><span class=mord ><span class=mtable ><span class=col-align-r ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.6em;"><span style="top:-3.6em;"><span class=pstrut  style="height:3.45em;"></span><span class=mord ><span class="mord text"><span class=mord >KL divergence term in ELBO</span></span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mord ><span class=mord  style="color:grey;"><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.3214em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord  style="color:grey;"><span class=mord  style="color:grey;">2</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="color:grey;border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord  style="color:grey;"><span class=mord  style="color:grey;">1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mord  style="color:grey;"><span class="delimsizing size3" style="color:grey;"><span style="color:grey;">[</span></span></span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mop >lo<span style="margin-right:0.01389em;">g</span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.3214em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mop >det</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >Σ</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mord ><span class="mord mathnormal" style="color:grey;">n</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin  style="color:grey;">+</span><span class=mspace  style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="color:grey;">μ</span><span class=mord  style="color:grey;">⊤</span><span class="mord mathnormal" style="color:grey;">μ</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin  style="color:grey;">+</span><span class=mspace  style="margin-right:0.2222em;"></span><span class="mord text" style="color:grey;"><span class=mord  style="color:grey;">trace</span></span><span class=mopen  style="color:grey;">(</span><span class=mord  style="color:grey;">Σ</span><span class=mclose  style="color:grey;">)</span><span class=mord  style="color:grey;"><span class="delimsizing size3" style="color:grey;"><span style="color:grey;">]</span></span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.1em;"><span></span></span></span></span></span></span></span></span></span></span></span> <p>&#40;<span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">μ</span></span></span></span> and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant=normal >Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class=mord >Σ</span></span></span></span> are mean and covariance of a variational distribution, and they are part of the model parameters in SVGP&#41; In this context, we will disregard the grey terms as they are easily handled by Zygote.</p> <h3 id=differentiate_the_log-determinant_of_a_matrix_using_zygotejl ><a href="#differentiate_the_log-determinant_of_a_matrix_using_zygotejl" class=header-anchor >Differentiate the log-determinant of a matrix using Zygote.jl</a></h3> <p>When <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant=normal >Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class=mord >Σ</span></span></span></span> is stored in CPU memory, the term <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><mi>det</mi><mo>⁡</mo><mi mathvariant=normal >Σ</mi></mrow><annotation encoding="application/x-tex">\log\det\Sigma</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8889em;vertical-align:-0.1944em;"></span><span class=mop >lo<span style="margin-right:0.01389em;">g</span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mop >det</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >Σ</span></span></span></span> involving the &#40;positive definite&#41; matrix <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant=normal >Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class=mord >Σ</span></span></span></span> works fine with Zygote.</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> Zygote
X = randn(<span class=hljs-number >3</span>,<span class=hljs-number >3</span>); XᵀX = X&#x27;X
f(x) = logdet(x)
<span class=hljs-meta >@show</span> gradient(f, XᵀX)[<span class=hljs-number >1</span>]</code></pre> <p>This gives:</p> <pre><code class="julia hljs">(gradient(f, XᵀX))[<span class=hljs-number >1</span>] = [<span class=hljs-number >0.8429186329377117</span> -<span class=hljs-number >0.4507909324777994</span> -<span class=hljs-number >0.7811665008998808</span>; -<span class=hljs-number >0.45079093247779933</span> <span class=hljs-number >0.48173303692414393</span> <span class=hljs-number >0.47267755816965557</span>; -<span class=hljs-number >0.7811665008998809</span> <span class=hljs-number >0.4726775581696556</span> <span class=hljs-number >1.261152638854635</span>]</code></pre>
<p>But interestingly, it does not work at all when <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant=normal >Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class=mord >Σ</span></span></span></span> is stored in GPU memory.</p>
<pre><code class="julia hljs"><span class=hljs-keyword >using</span> CUDA
CUDA.allowscalar(<span class=hljs-literal >false</span>)
<span class=hljs-meta >@show</span> gradient(f, cu(XᵀX))[<span class=hljs-number >1</span>]</code></pre>
<p>This will return:</p>
<code>Error: Scalar indexing is disallowed.</code>
<p>Let&#39;s try to get around this, using the <a href="https://blogs.sas.com/content/iml/2012/10/31/compute-the-log-determinant-of-a-matrix.html">Cholesky decomposition to calculate the log determinant</a> of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant=normal >Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class=mord >Σ</span></span></span></span>:</p>
<pre><code class="julia hljs">cholesky_log_det(X) = <span class=hljs-keyword >begin</span>
    C = cholesky(X)
    <span class=hljs-keyword >return</span> <span class=hljs-number >2</span>*sum(log.(diag(C.L)))
<span class=hljs-keyword >end</span>
<span class=hljs-meta >@show</span> gradient(cholesky_log_det, cu(XᵀX))[<span class=hljs-number >1</span>]</code></pre>
<p>But this again gives:</p>
<code>Error: Scalar indexing is disallowed.</code>
<h3 id=customized_adjoint_to_the_rescue ><a href="#customized_adjoint_to_the_rescue" class=header-anchor >Customized adjoint to the rescue</a></h3>
<p>It turns out that <a href="https://statisticaloddsandends.wordpress.com/2018/05/24/derivative-of-log-det-x/">the derivative of the log-determinant of a matrix has a very simple formula</a>, i.e., for an invertible matrix <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span></span></span></span>, we have that </p>
<span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mtable rowspacing=0.25em  columnalign=right  columnspacing=""><mtr><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mo stretchy=false >(</mo><mi>log</mi><mo>⁡</mo><mi>det</mi><mo>⁡</mo><mi>Z</mi><msup><mo stretchy=false >)</mo><mo mathvariant=normal  lspace=0em  rspace=0em >′</mo></msup><mo>=</mo><msup><mi>Z</mi><mrow><mo>−</mo><mi>T</mi></mrow></msup></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex"> \begin{align*}
    (\log\det Z)&#x27; = Z⁻ᵀ
    \end{align*}
</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.5513em;vertical-align:-0.5257em;"></span><span class=mord ><span class=mtable ><span class=col-align-r ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.0257em;"><span style="top:-3.1343em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mopen >(</span><span class=mop >lo<span style="margin-right:0.01389em;">g</span></span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mop >det</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class=mclose ><span class=mclose >)</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.5257em;"><span></span></span></span></span></span></span></span></span></span></span></span>
<p>Using this handy fact, let&#39;s go ahead and <a href="https://fluxml.ai/Zygote.jl/stable/adjoints/">make a customized adjoint</a>:</p>
<pre><code class="julia hljs"><span class=hljs-keyword >using</span> Zygote: <span class=hljs-meta >@adjoint</span>

<span class=hljs-keyword >function</span> log_determinant(Q::CuMatrix)
    A = cholesky(Q)
    <span class=hljs-keyword >return</span> <span class=hljs-number >2</span>*sum(log.(diag(A.L)))
<span class=hljs-keyword >end</span>

<span class=hljs-meta >@adjoint</span> <span class=hljs-keyword >function</span> log_determinant(Q::CuMatrix)
    <span class=hljs-comment ># Q positive definite so Q = LLᵀ by cholesky and thus Q⁻¹ = L⁻ᵀL⁻¹</span>
    <span class=hljs-comment ># numerically stable way to invert a covariance matrix: https://mathoverflow.net/questions/9001/inverting-a-covariance-matrix-numerically-stable</span>
    A = cholesky(Q)
    L_inv = inv(A.L)
    A_inv = L_inv&#x27;L_inv  
    <span class=hljs-keyword >return</span> <span class=hljs-number >2</span>*sum(log.(diag(A.L))), △ -&gt; (△ * A_inv&#x27;, )
<span class=hljs-keyword >end</span>

<span class=hljs-meta >@show</span> gradient(log_determinant, cu(XᵀX))[<span class=hljs-number >1</span>]</code></pre>
<p>And now we have:</p>
<pre><code class="julia hljs">(gradient(log_determinant, cu(XᵀX)))[<span class=hljs-number >1</span>] = <span class=hljs-built_in >Float32</span>[<span class=hljs-number >0.8429185</span> -<span class=hljs-number >0.4507908</span> -<span class=hljs-number >0.78116626</span>; -<span class=hljs-number >0.4507908</span> <span class=hljs-number >0.48173293</span> <span class=hljs-number >0.4726774</span>; -<span class=hljs-number >0.78116626</span> <span class=hljs-number >0.4726774</span> <span class=hljs-number >1.2611524</span>]</code></pre>
<p>This works. A quick check with the CPU version&#39;s result shows that our adjoint is returning the correct gradient of the log determinant of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant=normal >Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class=mord >Σ</span></span></span></span>.</p>
<p>A side note: You may have noticed the line <code>L_inv &#61; inv&#40;A.L&#41;</code>. Indeed, the inversion of a triangular matrix <code>A.L</code> still has quadratic time complexity, which is pretty darn slow for big matricies. Fortunately, in SVGP, the matrix <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant=normal >Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class=mord >Σ</span></span></span></span>, i.e. the input matrix <code>Q</code> above is defined using what&#39;s called the &quot;inducing points&quot;, which makes <code>Q</code> small. And because the inducing points is part of the model parameter of SVGP, you actually get to control the size of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant=normal >Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class=mord >Σ</span></span></span></span>.</p>
<p>An adjoint example is <a href="https://discourse.julialang.org/t/zygote-meaning-of-adjoint-add-a-b-add-a-b/36707/4">here</a> by Pbellive.</p>
<p>Note: This post is done on Zygote version 0.6.61 and Julia version 1.9.</p>
<p><hr /> update: 4/4/2024</p>
<p>The following code using <code>ChainRulesCore</code> produces the same result.</p>
<pre><code class="julia hljs"><span class=hljs-keyword >function</span> log_determinant(Q::CuMatrix)
    A = cholesky(Q)
    <span class=hljs-keyword >return</span> <span class=hljs-number >2</span>*sum(log.(diag(A.L)))
<span class=hljs-keyword >end</span>

<span class=hljs-keyword >function</span> ChainRulesCore.rrule(::typeof(log_determinant), Q::CuMatrix)
    A = cholesky(Q)
    L_inv = inv(A.L)
    A_inv = L_inv&#x27; * L_inv
    <span class=hljs-keyword >function</span> log_determinant_pullback(R̄)
        f̄ = NoTangent()
        Q̄ = R̄ * A_inv&#x27;
        <span class=hljs-keyword >return</span> f̄, Q̄
    <span class=hljs-keyword >end</span>
    <span class=hljs-keyword >return</span> <span class=hljs-number >2</span>*sum(log.(diag(A.L))), log_determinant_pullback
<span class=hljs-keyword >end</span></code></pre>
<div class=page-foot >
    Contact me by <a href="mailto:sc5502@cumc.columbia.edu">E-mail</a> | <a href="https://github.com/kchu25">Github</a> | <a href="https://www.linkedin.com/in/kchu1/">Linkedin</a>
    <br>
    This work is licensed under <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>.  Last modified: September 17, 2025.
    <br>
    Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia language</a>.
</div>
</div>
    
        



    
    
        <script src="/libs/highlight/highlight.min.js"></script>
<script>hljs.highlightAll();hljs.configure({tabReplace: '    '});</script>